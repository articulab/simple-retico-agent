from asyncio import Queue
import csv
import datetime
import os
import sys
import keyboard

from utils import *
from retico_core import *
from MicrophoneModule_PTT import MicrophoneModule_PTT
from whisperasr_2 import WhisperASRModule_2
from llama_cpp_memory_incremental import LlamaCppMemoryIncrementalModule
from coqui_tts import CoquiTTSModule
from SpeakerModule_2 import SpeakerModule_2


def main_demo():
    """
    The `main_demo` function creates and runs a dialog system that is able to have a conversation with the user.

    The dialog system is composed of different modules:
    - a Microphone : captures the user's voice
    - an ASR : transcribes the user's voice into text
    - a LLM : generates a textual answer to the trancription from user's spoken sentence.
    - a TTS : generates a spoken answer from the LLM's textual answer.
    - a Speaker : outputs the spoken answer generated by the system.

    We provide the system with a scenario (contained in the "system_prompt") that it will follow through the conversation :
    The system is a teacher and it will teach mathematics to a 8-year-old child student (the user)

    the parameters defined :
    - model_path : the path to the weights of the LLM that will be used in the dialog system.
    - system_prompt : a part of the prompt that will be given to the LLM at every agent turn to set the scenario of the conversation.
    - printing : an argument that set to True will print a lot of information useful for degugging.
    - rate : the target audio signal rate to which the audio captured by the microphone will be converted to (so that it is suitable for every module)
    - frame_length : the chosen frame length in seconds at which the audio signal will be chunked.
    - log_folder : the path to the folder where the logs (information about each module's latency) will be saved.

    It is recommended to not modify the rate and frame_length parameters because the modules were coded with theses values
    and it is not ensured that the system will run correctly with other values.
    """

    # parameters definition
    model_path = "./models/mistral-7b-instruct-v0.2.Q4_K_S.gguf"
    system_prompt = b"This is a spoken dialog scenario between a teacher and a 8 years old child student.\
        The teacher is teaching mathemathics to the child student.\
        As the student is a child, the teacher needs to stay gentle all the time. Please provide the next valid response for the followig conversation.\
        You play the role of a teacher. Here is the beginning of the conversation :"
    printing = False
    log_folder = create_new_log_folder("logs/demo/16k/")
    rate = 16000
    frame_length = 0.02

    # create modules
    mic = MicrophoneModule_PTT(rate=rate, frame_length=frame_length)
    asr = WhisperASRModule_2(
        printing=printing,
        full_sentences=True,
        input_framerate=rate,
        log_folder=log_folder,
    )
    llama_mem_icr = LlamaCppMemoryIncrementalModule(
        model_path,
        None,
        None,
        None,
        system_prompt,
        printing=printing,
        log_folder=log_folder,
    )
    tts = CoquiTTSModule(
        language="en", model="vits_neon", printing=printing, log_folder=log_folder
    )
    speaker = SpeakerModule_2(rate=tts.samplerate, log_folder=log_folder)

    # create network
    mic.subscribe(asr)
    asr.subscribe(llama_mem_icr)
    llama_mem_icr.subscribe(tts)
    tts.subscribe(speaker)

    # running network with the Push To Talk system
    try:
        network.run(mic)
        print("woz Running")
        quit_key = False
        while not quit_key:
            if keyboard.is_pressed("q"):
                quit_key = True
            time.sleep(1)
        network.stop(mic)
        merge_logs(log_folder)
    except Exception as err:
        print(f"Unexpected {err=}, {type(err)=}")
        network.stop(mic)


if __name__ == "__main__":
    main_demo()
